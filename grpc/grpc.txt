1. RPC 框架的目标就是让远程服务调用更加简单、透明，RPC 框架负责屏蔽底层的传输方式（TCP 或者 UDP）、
序列化方式（XML/Json/ 二进制）和通信细节。服务调用者可以像调用本地接口一样调用远程的服务提供者，
而不需要关心底层通信细节和调用过程。

2. GRPC 是一个高性能、开源和通用的 RPC 框架，面向服务端和移动端，基于 HTTP/2 设计。
GRPC 首先满足二进制和跨语言这两条，二进制说明压缩效率高，跨语言说明更灵活。
但是又是二进制，又是跨语言，这就相当于两个人沟通，你不但说方言，还说缩略语，人家怎么听懂呢？
所以，最好双方弄一个协议约定文件，里面规定好双方沟通的专业术语，这样沟通就顺畅多了。

3. 对于 GRPC 来讲，二进制序列化协议是 Protocol Buffers。首先，需要定义一个协议文件.proto：
syntax = “proto3”;
package com.geektime.grpc
option java_package = “com.geektime.grpc”;
message Order {
  required string date = 1;
  required string classname = 2;
  required string author = 3;
  required int price = 4;
}

message OrderResponse {
  required string message = 1;
}

service PurchaseOrder {
  rpc Purchase (Order) returns (OrderResponse) {}
}
首先指定使用 proto3 的语法，然后我们使用 Protocol Buffers 的语法，定义两个消息的类型，一个是发出去的参数，
一个是返回的结果。里面的每一个字段，例如 date、classname、author、price 都有唯一的一个数字标识，
这样在压缩的时候，就不用传输字段名称了，只传输这个数字标识就行了，能节省很多空间。
最后定义一个 Service，里面会有一个 RPC 调用的声明。

无论使用什么语言，都有相应的工具生成客户端和服务端的 Stub 程序，这样客户端就可以像调用本地一样，调用远程的服务了。

4. 协议约定
Protocol Buffers 是一款压缩效率极高的序列化协议，有很多设计精巧的序列化方法。
对于 int 类型 32 位的，一般都需要 4 个 Byte 进行存储。在 Protocol Buffers 中，使用的是变长整数的形式。
对于每一个 Byte 的 8 位，最高位都有特殊的含义。如果该位为 1，表示这个数字没完，后续的 Byte 也属于这个数字；
如果该位为 0，则这个数字到此结束。其他的 7 个 Bit 才是用来表示数字的内容。
因此，小于 128 的数字都可以用一个 Byte 表示；大于 128 的数字，比如 130，会用两个字节来表示。
对于每一个字段，使用的是 TLV（Tag，Length，Value）的存储办法。

其中 Tag = (field_num << 3) | wire_type。
field_num 就是在 proto 文件中，给每个字段指定唯一的数字标识，而 wire_type 用于标识后面的数据类型。

例如，对于 string author = 3，在这里 field_num 为 3，string 的 wire_type 为 2，
于是 (field_num << 3) | wire_type = (11000) | 10 = 11010 = 26；
接下来是 Length，最后是 Value 为“liuchao”，如果使用 UTF-8 编码，长度为 7 个字符，因而 Length 为 7。
可见，在序列化效率方面，Protocol Buffers 简直做到了极致。

灵活性方面，这种基于协议文件的二进制压缩协议往往存在更新不方便的问题。
例如，客户端和服务器因为需求的改变需要添加或者删除字段。这一点上，Protocol Buffers 考虑了兼容性。
在.proto协议文件中，每一个字段都有修饰符。比如：
required：这个值不能为空，一定要有这么一个字段出现；
optional：可选字段，可以设置，也可以不设置，如果不设置，则使用默认值；
repeated：可以重复 0 到多次。
如果我们想修改协议文件，对于赋给某个标签的数字，例如 string author=3，这个就不要改变了，改变了就不认了；
也不要添加或者删除 required 字段，因为解析的时候，发现没有这个字段就会报错。
对于 optional 和 repeated 字段，可以删除，也可以添加。这就给了客户端和服务端升级的可能性。

5. 网络传输
1）如果是 Java 技术栈，GRPC 的客户端和服务器之间通过 Netty Channel 作为数据通道，
2）GRPC每个请求都被封装成 HTTP2.0 的 Stream。
3) GPRC基于HTTP2.0,有4种服务模式：
    第一种，也是最常用的方式是单向 RPC，即客户端发送一个请求给服务端，从服务端获取一个应答，就像一次普通的函数调用。
    第二种方式是服务端流式RPC，即服务端返回的不是一个结果，而是一批。客户端发送一个请求给服务端，
可获取一个数据流用来读取一系列消息。客户端从返回的数据流里一直读取，直到没有更多消息为止。
    第三种方式为客户端流式RPC，也即客户端的请求不是一个，而是一批。
客户端用提供的一个数据流写入并发送一系列消息给服务端。一旦客户端完成消息写入，就等待服务端读取这些消息并返回应答。
    第四种方式为双向流式RPC，即两边都可以分别通过一个读写数据流来发送一系列消息。
这两个数据流操作是相互独立的，所以客户端和服务端能按其希望的任意顺序读写，服务端可以在写应答前等待所有的客户端消息，
或者它可以先读一个消息再写一个消息，或者读写相结合的其他方式。每个数据流里消息的顺序会被保持。

基于 HTTP  2.0，客户端和服务器之间的交互方式要丰富得多，不仅可以单方向远程调用，
还可以实现当服务端状态改变的时候，主动通知客户端。

6. 服务发现和治理
其实负载均衡本身比较简单，LVS、HAProxy、Nginx 都可以做，
关键问题是如何发现服务端，并根据服务端的变化，动态修改负载均衡器的配置。
一种对于 GRPC 支持比较好的负载均衡器 Envoy。其实 Envoy 不仅仅是负载均衡器，
它还是一个高性能的 C++ 写的 Proxy 转发器，可以配置非常灵活的转发规则。

这些规则可以是静态的，放在配置文件中的，在启动的时候加载。要想重新加载，一般需要重新启动，
Envoy 支持热加载和热重启，这在一定程度上缓解了这个问题。
更好的方式是将规则设置为动态的，放在统一的地方维护。
这个统一的地方在 Envoy 眼中被称为服务发现（Discovery Service），过一段时间去这里拿一下配置，就修改了转发策略。

无论是静态的，还是动态的，在配置里面往往会配置四个东西。
第一个是 listener。Envoy 既然是 Proxy，专门做转发，就得监听一个端口，接入请求，然后才能够根据策略转发，
这个监听的端口就称为 listener。
第二个是 endpoint，是目标的 IP 地址和端口。这个是 Proxy 最终将请求转发到的地方。
第三个是 cluster。一个 cluster 是具有完全相同行为的多个 endpoint，也即如果有三个服务端在运行，
就会有三个 IP 和端口，但是部署的是完全相同的三个服务，它们组成一个 cluster，从 cluster 到 endpoint 的过程称为负载均衡，可以轮询。
第四个是 route。有时候多个 cluster 具有类似的功能，但是是不同的版本号，可以通过 route 规则，
选择将请求路由到某一个版本号，也即某一个 cluster。

如果是静态的，则将后端的服务端的 IP 地址拿到，然后放在配置文件里面就可以了。
如果是动态的，就需要配置一个服务发现中心，这个服务发现中心要实现Envoy的API，
Envoy可以主动去服务发现中心拉取转发策略。

Envoy进程和服务发现中心之间要经常相互通信，互相推送数据，所以Envoy在控制面和服务发现中心沟通的时候，
就可以使用GRPC，也就天然具备在用户面支撑GRPC的能力。

Envoy如果复杂的配置，都能干什么事呢？
一种常见的规则是配置路由策略。例如后端的服务有两个版本，可以通过配置 Envoy 的 route，来设置两个版本之间，
也即两个 cluster 之间的 route 规则，一个占 99% 的流量，一个占 1% 的流量。
另一种常见的规则就是负载均衡策略。对于一个 cluster 下的多个 endpoint，可以配置负载均衡机制和健康检查机制，
当服务端新增了一个，或者挂了一个，都能够及时配置 Envoy，进行负载均衡。

所有这些节点的变化都会上传到注册中心，所有这些策略都可以通过注册中心进行下发，
所以，更严格的意义上讲，注册中心可以称为注册治理中心。

如果我们的应用能够意识不到服务治理的存在，就可以直接进行 GRPC 的调用。
这就是未来服务治理的趋势 Serivce Mesh，也即应用之间的相互调用全部由 Envoy 进行代理，
服务之间的治理也被 Envoy 进行代理，完全将服务治理抽象出来，到平台层解决。

7. protobuf代码生成
1）先从官网下载对应操作系统的的protoc工具，并配置到环境变量中。
https://github.com/protocolbuffers/protobuf/releases
2）你会发现工具中并没有go语言，但是有Java,JS,C++等等。
这时候可以go get github.com/golang/protobuf/protoc-gen-go
于是在GOPATH的bin目录会多一个protoc-gen-go.exe
这一步有可能会因为网络原因没法执行，可以从
https://github.com/golang/protobuf
下载源码，将protobuf下的内容，放到GOPATH的src/github.com/golang/protobuf里，然后
进入protoc-gen-go目录，执行go install，这样GOPATH的bin目录会多一个protoc-gen-go.exe。
3）执行 protoc --go_out=. *.proto
注意要把protoc-gen-go.exe也加入到环境变量。
生成文件若导入包有缺失，可以到这里下载https://github.com/protocolbuffers/protobuf-go